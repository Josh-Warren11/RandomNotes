{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2_NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Josh Warren"
      ],
      "metadata": {
        "id": "YXXU6sYRWt4i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0Kz0Nq4ui4"
      },
      "source": [
        "# Project \\#2 Starter Code\n",
        "Your project should address the categories below. \n",
        "\n",
        "## Problem:\n",
        "Given a large data set of positive and negative movie reviews, I am attempting to create machine learning algorithms that can learn if a review is negative or positive based on the diction used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZAVjcWhgBV"
      },
      "source": [
        "# Input Pipeline (sklearn):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "12XGv2fIfTSr",
        "outputId": "f37aff2f-6f46-4199-f605-fc8ebb38005b"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')\n",
        "data = pandas.read_csv('/content/drive/MyDrive/CS167/datasets/IMDB_dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICUC-PvQ5bP2"
      },
      "source": [
        "## Data Exploration:\n",
        "- Number of samples\n",
        "- Number of classes of the target variable\n",
        "- Number of words per sample\n",
        "- Distribution of sample length\n",
        "- Something else: get creative :) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following print statements and histogram allow viewers to have a better understanding of what the data looks like at a surface level."
      ],
      "metadata": {
        "id": "HRZ0_1wLBeqJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkCmgdf5ZqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "3175d747-73be-4db9-9242-027776396b42"
      },
      "source": [
        "## Use cells here to explore the data:\n",
        "import pylab as pl\n",
        "print(\"The shape of the data is:\",data.shape)\n",
        "\n",
        "pos = data[data['sentiment'] == 'negative']\n",
        "print(\"There are\",pos.shape[0], \"negative reviews in this data set\")\n",
        "\n",
        "pos = data[data['sentiment'] == 'positive']\n",
        "print(\"There are\",pos.shape[0], \"positive reviews in this data set\")\n",
        "\n",
        "count = data['review'].str.split().apply(len).value_counts()\n",
        "print(\"The median word count of any given review is\",count.median())\n",
        "\n",
        "print(\"The mean word count of any given reviews is\",count.mean())\n",
        "\n",
        "count.hist(figsize=[8,8],bins=20)\n",
        "pl.xlabel(\"Words\")\n",
        "pl.ylabel(\"Reviews\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the data is: (50000, 2)\n",
            "There are 25000 negative reviews in this data set\n",
            "There are 25000 positive reviews in this data set\n",
            "The median word count of any given review is 15.0\n",
            "The mean word count of any given reviews is 47.75549188156638\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Reviews')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSuguZ6u5lUl"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "I'm providing you with code that cleans the reviews by making it all lowercase letters and removing stop words. The three cells below do this for you. I still want you to explain what you did with the data here. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The nltk downloader allows you to work through the data and manipulate it the best you can for your needs. Stopwords allow the data to ignore commonly used words like \"a\" and \"the\"."
      ],
      "metadata": {
        "id": "WZGfRgULBzYH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV4FfvLegTSh",
        "outputId": "ad3a8db4-18be-4ede-dcbf-ff3b62e39bdb"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "#only do next line once\n",
        "nltk.download() #in Corpora tab, download stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "#The NLTK downloader will open, you need to select (d) for Download, and then 'stopwords'then (q) to quit"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEr6vRUgOUs"
      },
      "source": [
        "#This is a function that takes in a review, makes sure it is only lower case letters and removes stopwords.\n",
        "#It returns the cleaned review text.\n",
        "def clean_review(review):\n",
        "    #input is a string review\n",
        "    #return is review cleaned of all punctuation, lowercase, and removed nltk stopwords\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\",\" \",review)\n",
        "    lower_case = letters_only.lower()\n",
        "    words = lower_case.split()\n",
        "    for stop_word in stopwords.words(\"english\"):\n",
        "        while stop_word in words:\n",
        "            words.remove(stop_word)\n",
        "    cleaned = \" \".join(words)\n",
        "    return cleaned"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The block of code above allows all letters to be lowercased so the algorithms will be reading from a uniform data set. It also returns that cleaned data set, allowing it to be used for the rest of the code.\n",
        "\n",
        "\n",
        "Below, it is physically taking that cleaned data and assigning it to the array cleaned_text. This is done through a for loop."
      ],
      "metadata": {
        "id": "HcYgckGBCYVb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjHsILZgk9V"
      },
      "source": [
        "#process the data\n",
        "cleaned_text = []\n",
        "for i in range(len(data)):\n",
        "    cleaned_text.append(clean_review(data[\"review\"][i]))  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMg3P0ZNBvGM",
        "outputId": "1cdce44a-ee4f-4d05-be44-f9b6c2786a18"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one reviewers mentioned watching oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away br br would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side',\n",
              " 'wonderful little production br br filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece br br actors extremely well chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life br br realism really comes home little things fantasy guard rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done',\n",
              " 'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching light hearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point risk addiction thought proof woody allen still fully control style many us grown love br br laughed one woody comedies years dare say decade never impressed scarlet johanson managed tone sexy image jumped right average spirited young woman br br may crown jewel career wittier devil wears prada interesting superman great comedy go see friends',\n",
              " 'basically family little boy jake thinks zombie closet parents fighting time br br movie slower soap opera suddenly jake decides become rambo kill zombie br br ok first going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots br br well playing parents descent dialogs shots jake ignore',\n",
              " 'petter mattei love time money visually stunning film watch mr mattei offers us vivid portrait human relations movie seems telling us money power success people different situations encounter br br variation arthur schnitzler play theme director transfers action present time new york different characters meet connect one connected one way another next person one seems know previous point contact stylishly film sophisticated luxurious look taken see people live world live habitat br br thing one gets souls picture different stages loneliness one inhabits big city exactly best place human relations find sincere fulfillment one discerns case people encounter br br acting good mr mattei direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast make characters come alive br br wish mr mattei good luck await anxiously next work']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spDgSTvCg9wk"
      },
      "source": [
        "#establish training and testing dataset\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "    train_test_split(cleaned_text, data['sentiment'], test_size = 0.2, random_state=0) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "Becasue this is a classification, accuracy is the best way to measure the performance of our algorithm. "
      ],
      "metadata": {
        "id": "pyGiuA2NDLyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Planning**\n",
        "\n",
        "For this classification, I will be using Support Vector Classifier, Perceptron, and a Multilayer Perceptron for studying the data. I will also be running a Principal Componenet Analysis on one of the listed models above to see just how accurate I can create my best algorithm.\n",
        "\n",
        "For the Support Vector Classifier, I plan on tuning the random_state to randomize the data, and turning the kernal to linear to seperate the data.\n",
        "\n",
        "For the Perceptron model, I am going to tune the random state once again, and will also be changing the alpha to .0002 so the constant can be multiplies the regularization term by double the normal amount.\n",
        "\n",
        "For the MLP classifier, I will be tuning the random state to randomize the data, the hidden layer sizes to 100 to ensure there are 100 neurons in the ith layer, and the max iteration to 400, effectively doubling the number of iterations the data could possibly do. "
      ],
      "metadata": {
        "id": "EOqCSgprW7_2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-86AHOAkDpge"
      },
      "source": [
        "### Vectorizing the data\n",
        "\n",
        "**CountVectorizer**: Convert a collection of text documents to a matrix of token counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmex98NDgqJ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "\n",
        "#Bag of Words with 5000 most common words\n",
        "vectorizer = CountVectorizer(analyzer='word', max_features = 400)\n",
        "#find the right 5000 words\n",
        "vectorizer.fit(train_data)\n",
        "\n",
        "#use the vectorizer to transform review strings into word count vectors \n",
        "train_data_vectors = vectorizer.transform(train_data).toarray()\n",
        "test_data_vectors = vectorizer.transform(test_data).toarray()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Classifier**\n",
        "\n",
        "For this algorithm, I decided it would be the best to tune"
      ],
      "metadata": {
        "id": "uCg0KUh0IxQb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSQcsLOEAec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfbc216-f761-4ab1-a36d-68ddb87e7a1c"
      },
      "source": [
        "## Now use train_data_vectors and test_data_vectors to train/test/tune your sklearn models.\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = SVC(random_state= 41, kernel='linear')\n",
        "clf.fit(train_data_vectors,train_sln)\n",
        "predictions = clf.predict(test_data_vectors)\n",
        "print('Accuracy:',accuracy_score(test_sln,predictions))\n",
        "\n",
        "#vals = data[target].unique()\n",
        "#CM1 = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "#print(pd.DataFrame(CM1, index = \"True \" + vals, columns = \"Predicted \" + vals))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perceptron Model**\n",
        "\n",
        "For the Perceptron model I decided to tune the"
      ],
      "metadata": {
        "id": "eQJabgT0IBcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "perc = Perceptron(random_state= 40, alpha= .0002)\n",
        "perc.fit(train_data_vectors,train_sln)\n",
        "diagnosis_perc = perc.predict(test_data_vectors)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(test_sln, diagnosis_perc))\n",
        "#vals = data[target].unique()\n",
        "#CM3 = metrics.confusion_matrix(test_sln, diagnosis_perc, labels=vals)\n",
        "#print(pd.DataFrame(CM3, index = \"True \" + vals, columns = \"Predicted \" + vals))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSLOOmrzHjeu",
        "outputId": "5438599b-a66d-4a19-93ed-a6dae2b588e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-layered Perceptron**\n",
        "\n",
        "For the MLP algorithm the best results came from tuning"
      ],
      "metadata": {
        "id": "4tMdqiw2JSbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(random_state=41,hidden_layer_sizes = (100,), max_iter = 800)\n",
        "mlp.fit(train_data_vectors,train_sln)\n",
        "predictions = mlp.predict(test_data_vectors)\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(test_sln,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaugyWDQIAMP",
        "outputId": "dea2cd60-ce75-465c-e042-e898699e0cdb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Principal Component Analysis**\n",
        "\n",
        "For the PCA algorithm, I decided that tuning the"
      ],
      "metadata": {
        "id": "COPo4CriS6Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "extractor = PCA(n_components= 2, whiten=True)\n",
        "extractor.fit(train_data_vectors)\n",
        "train_data_transformed = extractor.transform(train_data_vectors)\n",
        "test_data_transformed = extractor.transform(test_data_vectors)\n",
        "\n",
        "clf2 = SVC(random_state= 41, kernel='linear')\n",
        "clf2.fit(train_data_vectors,train_sln)\n",
        "predictions = clf2.predict(test_data_vectors)\n",
        "print('Accuracy:',accuracy_score(test_sln,predictions))\n",
        "\n",
        "#vals = data[target].unique()\n",
        "#CM7 = metrics.confusion_matrix(test_sln, data_sgd_predictions3, labels=vals)\n",
        "#print(pd.DataFrame(CM7, index = \"True \" + vals, columns = \"Predicted \" + vals))\n",
        "\n",
        "#tdf = pd.DataFrame(train_data_transformed) \n",
        "#tdf['diagnosis'] = pd.Series(list(train_sln))\n",
        "#p_series = tdf[ tdf['Positive'] == 'P' ]\n",
        "#n_series = tdf[ tdf['Negative'] == 'N' ]\n",
        "\n",
        "#print(m_series)\n",
        "\n",
        "#plt.plot(m_series[0],m_series[1],'ro',label='')\n",
        "#plt.plot(b_series[0],b_series[1],'g^',label='Benign')\n",
        "#plt.legend(loc='best')\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "3lIf33GOTaxp",
        "outputId": "faa1b981-0c41-4d88-c5d5-0a237300943b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-16a50e5278dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhiten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_data_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_data_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_vectors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bumps in the road**\n",
        "\n",
        "I was not anticipating this code would take such a gruesomely long time to run. Once I learned how much time it took to run through this dataset I quickly determined I would have to sit down early in order to handle this dataset. I then realized that I could just go through 400-600 words and get nearly the same result so I started using 400 words to speed up the process and allow for better testing of variables.\n",
        "\n",
        "Figuring out which parameters to tune and what would be the best for the accuracy of the models was also tough. There are so many different options for tuning that you could probably create an extremely accurate model if you sat and toyed with it long enough. Or if you had a computer that was more high-powered than mine was during this project."
      ],
      "metadata": {
        "id": "gP1orb9yaJgA"
      }
    }
  ]
}